#!/usr/bin/env python3
import argparse, os, re, json, time, random, sqlite3, requests
from bs4 import BeautifulSoup
from urllib.parse import quote

# --- Signatures to detect ---
LEAK_PATTERNS = [
    re.compile(r"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}:[^\s]+"),  # email:password
    re.compile(r"\b\w+:\w+\b"),  # user:pass
]

# --- Blockchain explorers ---
EXPLORERS = {
    "btc": ["https://blockchair.com/bitcoin/address/{}", "https://www.blockchain.com/btc/address/{}"],
    "eth": ["https://etherscan.io/address/{}", "https://blockchair.com/ethereum/address/{}"],
    "sol": ["https://solscan.io/account/{}"],
    "xmr": ["https://xmrchain.net/search?value={}"],  # XMR support is limited
}

# --- Optional API integrations ---
BLOCKCHAIR_API_KEY = os.getenv("BLOCKCHAIR_API_KEY")
ETHERSCAN_API_KEY = os.getenv("ETHERSCAN_API_KEY")

# --- User agents ---
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/120.0",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) Safari/605.1.15",
    "Mozilla/5.0 (X11; Linux x86_64) Firefox/117.0",
]

# --- SQLite cache ---
def init_db(path):
    conn = sqlite3.connect(path)
    c = conn.cursor()
    c.execute("""CREATE TABLE IF NOT EXISTS cache (
                 url TEXT PRIMARY KEY,
                 timestamp INTEGER,
                 status TEXT
                 )""")
    conn.commit()
    return conn

def fetch_url(url, session, use_cache=True, conn=None):
    if use_cache and conn:
        cur = conn.cursor()
        cur.execute("SELECT status FROM cache WHERE url = ?", (url,))
        row = cur.fetchone()
        if row:
            return None  # skip cached
    try:
        headers = {"User-Agent": random.choice(USER_AGENTS)}
        r = session.get(url, headers=headers, timeout=20)
        status = "ok" if r.ok else f"err_{r.status_code}"
        if conn:
            conn.execute("INSERT OR REPLACE INTO cache VALUES (?, ?, ?)",
                         (url, int(time.time()), status))
            conn.commit()
        return r.text
    except Exception as e:
        if conn:
            conn.execute("INSERT OR REPLACE INTO cache VALUES (?, ?, ?)",
                         (url, int(time.time()), f"error:{e}"))
            conn.commit()
        return None

def search_patterns(html):
    findings = []
    for pattern in LEAK_PATTERNS:
        matches = pattern.findall(html)
        if matches:
            findings.extend(matches)
    return list(set(findings))

# --- Optional API enrichment ---
def enrich_blockchair(addr, chain):
    if not BLOCKCHAIR_API_KEY:
        return None
    chain_map = {"btc":"bitcoin","eth":"ethereum","sol":"solana","xmr":"monero"}
    api_chain = chain_map.get(chain)
    if not api_chain:
        return None
    url = f"https://api.blockchair.com/{api_chain}/dashboards/address/{addr}?key={BLOCKCHAIR_API_KEY}"
    try:
        r = requests.get(url, timeout=15, headers={"User-Agent": random.choice(USER_AGENTS)})
        if r.ok:
            return r.json()
        return {"error": f"status {r.status_code}"}
    except Exception as e:
        return {"error": str(e)}

def enrich_etherscan(addr):
    if not ETHERSCAN_API_KEY:
        return None
    url = f"https://api.etherscan.io/api?module=account&action=balance&address={addr}&tag=latest&apikey={ETHERSCAN_API_KEY}"
    try:
        r = requests.get(url, timeout=12, headers={"User-Agent": random.choice(USER_AGENTS)})
        if r.ok:
            return r.json()
        return {"error": f"status {r.status_code}"}
    except Exception as e:
        return {"error": str(e)}

# --- Recon for addresses ---
def recon_address(addr, chains, session, conn=None, use_cache=True):
    results = []
    for chain in chains:
        # API enrichment
        api_data = None
        if chain == "eth" and ETHERSCAN_API_KEY:
            api_data = enrich_etherscan(addr)
            results.append({"explorer_api":"etherscan","chain":chain,"data":api_data})
        if BLOCKCHAIR_API_KEY:
            api_data = enrich_blockchair(addr, chain)
            if api_data:
                results.append({"explorer_api":"blockchair","chain":chain,"data":api_data})

        # Web scraping
        for url_template in EXPLORERS.get(chain, []):
            url = url_template.format(addr)
            html = fetch_url(url, session, use_cache=use_cache, conn=conn)
            if html is None:
                continue
            leaks = search_patterns(html)
            results.append({"url": url, "matches": leaks})
            # save snapshot
            os.makedirs(f"reports/{addr}", exist_ok=True)
            with open(f"reports/{addr}/{chain}_{hash(url)}.html","w") as f:
                f.write(html)
            time.sleep(random.uniform(2,5))
    return results

# --- Recon for usernames via DuckDuckGo ---
def recon_username(username, session, conn=None, use_cache=True, limit=10):
    results = []
    query = quote(username)
    ddg_url = f"https://html.duckduckgo.com/html/?q={query}"
    html = fetch_url(ddg_url, session, use_cache=use_cache, conn=conn)
    if html:
        soup = BeautifulSoup(html, "lxml")
        for a in soup.find_all("a", href=True):
            url = a["href"]
            if "duckduckgo.com" in url:
                continue
            leaks = search_patterns(url)
            results.append({"url": url, "matches": leaks})
            if len(results) >= limit:
                break
    return results

# --- Main ---
def main():
    parser = argparse.ArgumentParser(
        description="Crypto Recon OSINT Tool - Search usernames or wallet addresses",
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument("--target","-t",required=True, help="Username or wallet address to investigate")
    parser.add_argument("--type","-y",required=True,choices=["username","address"], help="Target type")
    parser.add_argument("--chains","-c",default="btc,eth,sol,xmr", help="Comma-separated chains (default: all)")
    parser.add_argument("--db",default="cache.db", help="SQLite DB path for caching")
    parser.add_argument("--no-cache",action="store_true", help="Bypass cache for debugging")
    parser.add_argument("--limit",type=int,default=10, help="Max number of search results for username recon")
    args = parser.parse_args()

    chains = args.chains.split(",")
    session = requests.Session()
    conn = None if args.no_cache else init_db(args.db)

    results = {"target": args.target, "type": args.type, "results":[]}

    if args.type=="address":
        results["results"] = recon_address(args.target, chains, session, conn=conn, use_cache=not args.no_cache)
    else:
        results["results"] = recon_username(args.target, session, conn=conn, use_cache=not args.no_cache, limit=args.limit)

    with open(f"findings_{args.target}.json","w") as f:
        json.dump(results, f, indent=2)
    print(f"[*] Done. JSON saved to findings_{args.target}.json")

if __name__=="__main__":
    main()
